# Цель

Cоставить документацию процессов ETL на основе предложенного датасета

# Слои Хранилища
1) NDS 
 ![image](https://github.com/user-attachments/assets/cd307106-419b-4933-a9cf-9f1e5f38d044)

Хранит таблицы нормализованные по 3НФ. Предназначен для OLTP-нагрузки, отвечает за согласованность данных за счет соблюдения  Acid-принципа.  Хранит историчность в себе по типу CSD2 (например таблица nds.product)

2) DDS

![image](https://github.com/user-attachments/assets/2240ea7c-4354-47b8-8987-7209a361104f)
![image](https://github.com/user-attachments/assets/e52ba646-c3c2-42b6-aeea-ed712eaf5619)

Слой хранилища по типу "звезда". Содержит таблицы фактов и измерений. Предназначен для дальнейшей аналитической обработки.

3) Data mart
Хранит сами витрины для конечных потребителей, на их основе строятся дашборды.

# Формирование структуры 

Файл DDL.sql содержиn скрипты создания таблиц для трех слоев + отдельный слой метаданных meta в хранилище, где будет отображаться кол-во прогрузок и их статусы.

# ETL-процессы
Сформированы на основе python скриптов + sql функций.

1) etl_nds_0.py - Скрипт первоначально заполняет таблицы nds-слоя данными (без nds.invoice)
2) etl_nds_1.py- Скрипт заполняет nds.invoice. Часть данных "выдумывется" для наглядности процесса. Например, основная таблица с инвойсами. Там есть столбцы “тип клиента” и “пол клиента”. Тут транзитивная зависимость - они не зависят от инвойса, а от сущности “клиент”. Была создана отдельная таблицу с тремя столбцами - customer_id, customer_type, gender. Но в главной таблице нет никакого уникального идентификатора клиента. Поэтому было случайно сгенерировано распределение customer_id для главной таблицы.
3) dds_scripts.sql - содержит функцию загрузки таблицы факто, измерений + наполнение мета-таблицы со статусами прогрузок.

# Дашборд
Т.к. доступ в Табло ограничен для РФ, выбран другой доступный аналог - lookerstudio. 
Ссылка на демонстративный дашборд - https://lookerstudio.google.com/reporting/b3977c8f-7e75-4f4b-86af-95ee94543e85

